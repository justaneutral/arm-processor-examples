<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AWE Core 8.X.0 Documentation: AWE Core 8 Integration Guide</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">AWE Core 8.X.0 Documentation
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">AWE Core 8 Integration Guide </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p ><a class="anchor" id="md_Docs_AWECore_AWECore_MainPage"></a> </p><h1>Table of Contents</h1>
<ol type="1">
<li><a class="el" href="index.html#introduction">Introduction</a><ol type="a">
<li><a class="el" href="index.html#terms-defs">Terms and Definitions</a></li>
<li><a class="el" href="index.html#additional-docs">Additional Documentation</a></li>
</ol>
</li>
<li><a class="el" href="index.html#overview">Overview of Integration Steps</a></li>
<li><a class="el" href="index.html#include_linking">Including Headers and Link Libraries</a><ol type="a">
<li><a class="el" href="index.html#headers">Required Header Files</a></li>
<li><a class="el" href="index.html#libraries">Required Libraries</a></li>
<li><a class="el" href="index.html#helpercode">Helper Code</a></li>
</ol>
</li>
<li><a class="el" href="index.html#aweflashfsinstance-setup">Setting Up the AWE Flash FS Instance (Optional)</a><ol type="a">
<li><a class="el" href="index.html#fs-declaring">Declaring the Required Variables</a></li>
<li><a class="el" href="index.html#flash_callbacks">Defining the Required Callbacks</a></li>
<li><a class="el" href="index.html#fs-configuring">Configuring the AWE Flash FS Instance</a></li>
<li><a class="el" href="index.html#aweflashfsinstance_init">Initializing the AWE Flash FS Instance</a></li>
</ol>
</li>
<li><a class="el" href="index.html#aweinstance-setup">Setting Up the AWE Instance</a><ol type="a">
<li><a class="el" href="index.html#awe-declaring">Declaring the Required Variables</a></li>
<li><a class="el" href="index.html#awe-configuring">Configuring the AWE Instance</a></li>
<li><a class="el" href="index.html#iopin_init">Initializing the IO Pins</a></li>
<li><a class="el" href="index.html#aweinstance_init">Initializing the AWE Instance</a></li>
</ol>
</li>
<li><a class="el" href="index.html#tuning-interface">Setting up a Tuning Interface</a></li>
<li><a class="el" href="index.html#rtaudio">Realtime Audio</a><ol type="a">
<li><a class="el" href="index.html#rtaudio_intro">RT Audio Introduction</a></li>
<li><a class="el" href="index.html#rtaudio_steps">RT Audio Integration Steps</a></li>
<li><a class="el" href="index.html#rtaudio_sample_formats">Sample Formats and Converting to Fract32</a></li>
<li><a class="el" href="index.html#multirate">Multi-Rate Processing</a></li>
<li><a class="el" href="index.html#multirate-scheduling">Multi-Rate Scheduling</a></li>
<li><a class="el" href="index.html#multi-instance-scheduling">Multi-Instance Scheduling</a></li>
<li><a class="el" href="index.html#multirate-multiinstance-profiling">Multi-Rate and Multi-Instance Profiling</a></li>
<li><a class="el" href="index.html#profiling-correction-by-external-events">Preemption Overhead Outside of the Layout</a></li>
</ol>
</li>
<li><a class="el" href="index.html#deferred-processing">Deferred Processing</a></li>
<li><a class="el" href="index.html#standalone-operation">Standalone Operation</a><ol type="a">
<li><a class="el" href="index.html#load-array">Loading from an Array</a></li>
</ol>
</li>
<li><a class="el" href="index.html#scheduling-priority">AWE Core Scheduling and Priority</a></li>
<li><a class="el" href="index.html#ctrl-interface">Setting up a Control Interface</a><ol type="a">
<li><a class="el" href="index.html#ctrl-interface-overview">Control Interface Overview</a></li>
<li><a class="el" href="index.html#ctrl-interface-steps">Control Interface Steps</a></li>
</ol>
</li>
<li><a class="el" href="index.html#optimization">Optimization</a><ol type="a">
<li><a class="el" href="index.html#heap-sizing">Heap Sizing and Placement</a></li>
<li><a class="el" href="index.html#modulelist-optimization">Module List Optimization</a></li>
</ol>
</li>
<li><a class="el" href="index.html#multi-awe-instance">Multiple AWE Instances</a><ol type="a">
<li><a class="el" href="index.html#multi-awe-instance-intro">Multiple AWE Instances Introduction</a></li>
<li><a class="el" href="index.html#multi-instance-guide">Multi Instance Guide</a></li>
<li><a class="el" href="index.html#multi-canvas-guide">Multi Canvas Guide</a><ol type="i">
<li><a class="el" href="index.html#multi-canvas-tuning-setup">Multi Canvas Tuning Interface Setup</a></li>
<li><a class="el" href="index.html#multi-canvas-pseudocode">Multi Canvas Pseudocode Examples</a></li>
</ol>
</li>
</ol>
</li>
<li><a class="el" href="index.html#latency">Latency</a><ol type="a">
<li><a class="el" href="index.html#latency-overview">Overview of Latency in AWE Core</a></li>
<li><a class="el" href="index.html#latency-conditions">Conditions that Impact Latency</a><ol type="i">
<li><a class="el" href="index.html#latency-equal-blocksizes">Equivalent Block Sizes -- Double Buffering</a></li>
<li><a class="el" href="index.html#latency-api-order">Order of AWECore API Calls -- Import Pump Export</a></li>
<li><a class="el" href="index.html#latency-inline-pump">Pump Inline with Callback -- Pump Context</a></li>
</ol>
</li>
</ol>
</li>
<li><a class="el" href="index.html#troubleshooting">Troubleshooting and Common Pitfalls</a></li>
</ol>
<h2>Introduction <a class="anchor" id="introduction"></a></h2>
<p >This document is meant to be a "Quick-Start" on how to integrate AWE Core. Advanced concepts are left out. Before reading this document, please see the <a class="el" href="a00086.html">Theory Of Operation</a> document.</p>
<p >The AWE Core™ is a hardware-independent, reconfigurable audio-processing engine. The AWE Core includes over 400 audio-processing Modules, from mixers and filters to compressors and FFTs, that can be combined to easily create complex signal processing flows. The AWE Core operates by passing audio through a user-defined sequence of these Modules, as directed by Configuration-data at run-time.</p>
<h3>Terms and Definitions<a class="anchor" id="terms-defs"></a></h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Term   </th><th class="markdownTableHeadNone">Definition    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">API   </td><td class="markdownTableBodyNone">Application Interface    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">AWE Instance   </td><td class="markdownTableBodyNone">The main AWE Core object    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Tuning Interface   </td><td class="markdownTableBodyNone">The interface by which commands/replies are transferred    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Layout   </td><td class="markdownTableBodyNone">Audio Weaver signal processing flow    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Sub-Layout   </td><td class="markdownTableBodyNone">Clock-divided section of a layout    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">AWB   </td><td class="markdownTableBodyNone">Audio Weaver Binary File    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">AWD   </td><td class="markdownTableBodyNone">Audio Weaver Design File    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">AWE   </td><td class="markdownTableBodyNone">Audio Weaver    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">AWS   </td><td class="markdownTableBodyNone">Audio Weaver Script File    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">BSP   </td><td class="markdownTableBodyNone">Board Support Package    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">IPC   </td><td class="markdownTableBodyNone">Inter Process Communication    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">RTOS   </td><td class="markdownTableBodyNone">Realtime operating system    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">RT   </td><td class="markdownTableBodyNone">Real-time   </td></tr>
</table>
<h3>Additional Documentation<a class="anchor" id="additional-docs"></a></h3>
<p >This document will go over the basics of integrating the AWE Core. It also includes a Doxygen-generated map of all the available API Functions, Macros, Data Structures, etc. <a class="el" href="a00044.html">API Doc</a>.</p>
<p >For a brief view of the API, see the 'AWECore_cheatsheet.pdf' in this package.</p>
<p >For a more detailed description of the Tuning Protocol and the various transport methods, please see the Tuning Protocol document <a class="el" href="a00085.html">here</a>.</p>
<h2>Overview of Integration Steps <a class="anchor" id="overview"></a></h2>
<p >Here are the basic steps to integrate AWE Core.</p><ol type="1">
<li>Include headers and link libraries</li>
<li>Define/allocate required variables</li>
<li>Configure the audio IO data structures</li>
<li>Initialize the API</li>
<li>Setup a tuning interface</li>
<li>Setup realtime audio</li>
<li>Setup a control interface (optional based on product intent)</li>
<li>Verify proper scheduling/priority.</li>
</ol>
<h2>Include Headers and Link Libraries <a class="anchor" id="include_linking"></a></h2>
<h3>Header Files <a class="anchor" id="headers"></a></h3>
<ul>
<li><a class="el" href="a00038.html">AWECore.h</a><ul>
<li>include's all of the required header files. Does not declare anything, only include's.</li>
</ul>
</li>
<li><a class="el" href="a00044.html">AWEInstance.h</a><ul>
<li>AWEInstance.h contains most of the API declarations and structs required for an integration. This serves as the central API document.</li>
</ul>
</li>
<li>TargetProcessor.h, and the Target-specific header file<ul>
<li>For instance, on an M7 DSPC will provide the file “ARM_CortexM7_TargetProcessor.h”.</li>
</ul>
</li>
<li><a class="el" href="a00056.html">StandardDefs.h</a><ul>
<li>Defines the AWE Core audio types</li>
</ul>
</li>
<li><a class="el" href="a00047.html">Errors.h</a><ul>
<li>When doing error checking on API calls, negative return values correspond to an error. The error can be determined by using the definitions in <a class="el" href="a00047.html">Errors.h</a>.</li>
</ul>
</li>
<li>ModuleList.h<ul>
<li>Every AWE Core deliverable contains a default ModuleList.h (in the SampleApp/[Target name]/Source folder) that includes a list of all the available modules. This file can be modified to account for custom modules, or modules that are not required for the target application.</li>
</ul>
</li>
</ul>
<h3>Required Libraries <a class="anchor" id="libraries"></a></h3>
<ul>
<li>AWECore<ul>
<li>This is the main AWE Core library.</li>
<li>The exact name and extension will vary from platform to platform, but will always have the basename "awecore".</li>
</ul>
</li>
</ul>
<h3>Helper Code / Optional <a class="anchor" id="helpercode"></a></h3>
<ul>
<li>AWECoreUtils (AWECoreUtils.c/<a class="el" href="a00041.html">AWECoreUtils.h</a>)<ul>
<li>AWECoreUtils contains various helper code including SPI/UART helper functions, a Multi-instance reply table generator, and a CRC computer for preparing custom replies to AWE Server. <a class="el" href="a00041.html">AWECoreUtils.h API Doc</a></li>
</ul>
</li>
<li>ProxyIDs.h<ul>
<li>ProxyIDs.h contains a list of all the AWE Core tuning commands. <a class="el" href="a00050.html">ProxyIDs.h</a></li>
</ul>
</li>
<li>Additional Module Pack Libraries<ul>
<li>Additional module pack libraries can be linked in (VUI modules, 3rd party custom modules, etc).</li>
</ul>
</li>
</ul>
<h2>Setting up the AWE Flash FS Instance (Optional) <a class="anchor" id="aweflashfsinstance-setup"></a></h2>
<h3>Declaring the Required Variables <a class="anchor" id="fs-declaring"></a></h3>
<p >A number of variables must be defined before configuring/initializing the AWE Flash File System (FS) Instance. <a class="el" href="a00053.html">FlashFSInstance.h</a></p>
<ul>
<li>The <a class="el" href="a00053.html#ae8ec7ae5a5cf8b4417f114378458ef3f">AWEFlashFSInstance</a> object encapsulates a single AWE Flash File System instance. It must be defined so it doesn't go out of scope, for example as static or global, and be initialized to zeros. <pre class="fragment"> //declare and initialize to zeros
 AWEFlashFSInstance g_AWEFlashFSInstance = {0};
</pre></li>
<li>Define the following macros for flash memory size in bytes, erasable block (or segment) size and the start offset for the Flash File System. Make sure the start offset does not overlap with other data in the Flash device, like application loader file etc. It’s recommended to use the available free space in the flash from the end. Following are the example macros of a 64MB flash device. <pre class="fragment"> // Specify flash memory available for flash file system
 #define FLASH_MEMORY_SIZE_IN_BYTES 0x4000000
 #define ERASEABLE_SECTOR_SIZE 0x10000
 // 704KB from the beginning is for application loader file
 #define FILE_SYSTEM_START_OFFSET 0xB0000
 #define SECTOR_ERASE_TIME_MS    400
</pre></li>
</ul>
<p >Later, in the initialization section, it will become clear that there are several fields of the <a class="el" href="a00053.html#ae8ec7ae5a5cf8b4417f114378458ef3f">AWEFlashFSInstance</a> structure that must be configured before it can be used.</p>
<h3>Defining the Required Callbacks <a class="anchor" id="flash_callbacks"></a></h3>
<p >AWE Flash File System requires callbacks they must be defined before initializing the AWE Flash FS Instance.</p>
<ul>
<li>Init callback to handle any flash device specific configuration. This is called during initialization time (awe_init) and every time Erase Flash is triggered. Following is a sample 'init' callback. <pre class="fragment"> ///-----------------------------------------------------------------------------
 /// @name  BOOL usrInitFlashFileSystem(void)
 /// @brief Callback to initialize Flash device
 ///
 /// @retval     TRUE  - Initialization is success
 /// @retval     FALSE - Initialization failed
 ///-----------------------------------------------------------------------------
 BOOL usrInitFlashFileSystem(void)
 {
     // Implement any flash specific initializations
     // Return FALSE up on failure

     return 1;
 }   // End usrInitFlashFileSystem
</pre></li>
<li>Read callback to fetch requested words from the flash. Following is a sample 'Read' callback. <pre class="fragment"> ///-----------------------------------------------------------------------------
 /// @name  BOOL usrReadFlashMemory(UINT32 nAddress, UINT32 * pBuffer, UINT32 nDWordsToRead)
 /// @brief Read 4-byte words from flash memory
 ///
 /// @param[in]  UINT32  nAddress - address in flash to start reading
 /// @param[in]  UINT32 *pBuffer  - buffer to read into
 /// @param[in]  UINT32  nDWordsToRead - number of 4-bytes elements to read
 ///
 /// @retval     TRUE  - read succeeded
 /// @retval     FALSE - read failed
 ///-----------------------------------------------------------------------------
 BOOL usrReadFlashMemory(UINT32 nAddress, UINT32 * pBuffer, UINT32 nDWordsToRead)
 {
     // Check for the count zero and skip remaining
     if(nDWordsToRead == 0)
     {
         return 1;
     }

     // Flash specific read implementation
     // Return FALSE up on failure

     return 1;

 }   // End usrReadFlashMemory
</pre></li>
<li>Write callback to write requested words on to the flash. Following is a sample 'Write' callback. <pre class="fragment"> ///-----------------------------------------------------------------------------
 /// @name  BOOL usrWriteFlashMemory(UINT32 nAddress, UINT32 * pBuffer, UINT32 nDWordsToWrite)
 /// @brief Write 4-byte words to flash memory
 ///
 /// @param[in]  UINT32  nAddress - address in flash to start writing
 /// @param[in]  UINT32 * pBuffer  - buffer to write into
 /// @param[in]  UINT32  nDWordsToWrite - number of 4-bytes elements to write
 ///
 /// @retval     TRUE  - write succeeded
 /// @retval     FALSE - write failed
 ///-----------------------------------------------------------------------------
 BOOL usrWriteFlashMemory(UINT32 nAddress, UINT32 * pBuffer, UINT32 nDWordsToWrite)
 {
     // Check for the count zero and skip remaining
     if(nDWordsToWrite == 0)
     {
         return 1;
     }

     // Flash device write specific implementation
     // Return FALSE up on failure

     return 1;

 }   // End usrWriteFlashMemory
</pre></li>
<li>Erase callback to erase flash sectors. Following is a sample 'Erase' callback. <pre class="fragment"> ///-----------------------------------------------------------------------------
 /// @name  BOOL usrEraseFlashSector(UINT32 nStartingAddress, UINT32 nNumberOfSectors)
 /// @brief Erase flash memory starting at address for number of sectors
 ///
 /// @param[in]  UINT32  nStartingAddress - address in flash to start erasing
 /// @param[in]  UINT32  nNumberOfSectors  - number of flash memory sectors to erase
 ///
 /// @retval     TRUE  - erase succeeded
 /// @retval     FALSE - erase failed
 ///-----------------------------------------------------------------------------
 BOOL usrEraseFlashSector(UINT32 nStartingAddress, UINT32 nNumberOfSectors)
 {
     UINT32 nSectorAddress, index;

     nSectorAddress = nStartingAddress;

     // Loop through number of sectors and erase each sector
     for (index = 0; index &lt; nNumberOfSectors; index++)
     {
         // Flash device specific sector erase implementation
         // with sector start address 'nSectorAddress'
         // Return FALSE up on failure

         // Go to next sector start address
         nSectorAddress += ERASEABLE_SECTOR_SIZE;
     }

     return 1;

 }   // End usrEraseFlashMemorySector
</pre> <h3>Configuring the AWE Flash FS Instance<a class="anchor" id="fs-configuring"></a></h3>
</li>
</ul>
<p >Now that the required variables have been declared, the AWE Flash FS Instance will be configured by assigning its members and pointers.</p>
<ul>
<li><p class="startli">First, ensure that the <a class="el" href="a00053.html#ae8ec7ae5a5cf8b4417f114378458ef3f">AWEFlashFSInstance</a> is initialized to zeros. If not, explicitly initialize to 0 with memset. </p><pre class="fragment">  memset(&amp;g_AWEFlashFSInstance, 0, sizeof(AWEFlashFSInstance) );
</pre><ul>
<li>Initialize the callback pointers of ‘cbInit’, ‘cbEraseSector’, ‘cbFlashWrite’ and ‘cbFlashRead’ in the AWE Flash FS Instance. <pre class="fragment"> g_AWEFlashFSInstance.cbInit = &amp;usrInitFlashFileSystem;
 g_AWEFlashFSInstance.cbEraseSector = &amp;usrEraseFlashMemorySector;
 g_AWEFlashFSInstance.cbFlashWrite = &amp;usrWriteFlashMemory;
 g_AWEFlashFSInstance.cbFlashRead = &amp;usrReadFlashMemory;
</pre></li>
<li>Initialize the flash specific settings of flash size in bytes, erasable block or sector size, start offset and block or sector erase time. <pre class="fragment"> g_AWEFlashFSInstance.flashSizeInBytes = FLASH_MEMORY_SIZE_IN_BYTES;
 g_AWEFlashFSInstance.flashErasableBlockSizeInBytes = ERASEABLE_SECTOR_SIZE;
 g_AWEFlashFSInstance.flashStartOffsetInBytes = FILE_SYSTEM_START_OFFSET;
 g_AWEFlashFSInstance.flashEraseTimeInMs = (INT32)((FLOAT32)((( (FLASH_MEMORY_SIZE_IN_BYTES - FILE_SYSTEM_START_OFFSET)/ ERASEABLE_SECTOR_SIZE)*SECTOR_ERASE_TIME_MS/1000) + 0.5f) + 5);
</pre> <h3>Initializing the AWE Flash FS Instance <a class="anchor" id="aweflashfsinstance_init"></a></h3>
</li>
</ul>
<p class="startli">Next, initialize the AWE Flash FS Instance by calling the <a class="el" href="a00044.html#a985924707ad2ac0c06eb792702783087">awe_initFlashFS()</a> function. **This must happen before calling <a class="el" href="a00044.html#ae4e7e278a5a4794714190415899d8022">awe_init()</a>.** If <a class="el" href="a00044.html#a985924707ad2ac0c06eb792702783087">awe_initFlashFS()</a> is called after <a class="el" href="a00044.html#ae4e7e278a5a4794714190415899d8022">awe_init</a>, the initialization will fail.</p>
<p class="startli">awe_initFlashFS(&amp;g_AWEInstance, &amp;g_AWEFlashFSInstance);</p><ul>
<li>Assign pFlashFileSystem in AWE Instance to AWE Flash FS instance. <pre class="fragment"> g_AWEInstance.pFlashFileSystem = &amp;g_AWEFlashFSInstance;
</pre></li>
</ul>
</li>
</ul>
<p >The code above will initialize the AWE Flash FS Instance.</p>
<h2>Setting up the AWE Instance <a class="anchor" id="aweinstance-setup"></a></h2>
<h3>Declaring the Required Variables <a class="anchor" id="awe-declaring"></a></h3>
<p >A number of variables must be defined before configuring/initializing the AWE Instance.</p>
<ul>
<li>The <a class="el" href="a00044.html#af3b70df7f9d672997e61999a024ba018">AWEInstance</a> object encapsulates a single AWE Core instance. Most API calls take an <a class="el" href="a00044.html#af3b70df7f9d672997e61999a024ba018">AWEInstance</a> as the first argument. It must be defined so it doesn't go out of scope, for example as static or global, and be initialized to zeros. <pre class="fragment"> //declare and initialize to zeros
 AWEInstance g_AWEInstance = {0};
</pre> Later, in the initialization section, it will become clear that there are several fields of the <a class="el" href="a00044.html#af3b70df7f9d672997e61999a024ba018">AWEInstance</a> structure that must be configured before it can be used to process audio data.</li>
<li>The IOPinDescriptor objects describe input and output data buffers and their properties. They must be defined so they don't go out of scope, for example as static. NOTE: multiple IO pins not supported. There can only be one input pin and one output pin. All API's that take the argument "pinIdx" will always pass in 0. <pre class="fragment"> static IOPinDescriptor aweInputPin;
 static IOPinDescriptor aweOutputPin;
</pre></li>
<li>A module descriptor table that contains an array of pointers to modules that are available to the AWE Instance. The table is initialized at compile time. It must be defined so they don't go out of scope, for example as static. <pre class="fragment"> //The list of class objects is defined in ModuleList.h
 const void* g_module_descriptor_table[] = { LISTOFCLASSOBJECTS};
</pre></li>
<li>Memory heaps that the AWE Core uses for its own local processing. The integrator must provide word-aligned blocks of memory that are persistent. For example, <pre class="fragment"> UINT32 g_FastHeapA[FAST_HEAP_A_SIZE];
 UINT32 g_FastHeapB[FAST_HEAP_B_SIZE];
 UINT32 g_SlowHeap[SLOW_HEAP_SIZE];
</pre> where FAST_HEAP_A_SIZE, FAST_HEAP_B_SIZE, and SLOW_HEAP_SIZE are chosen appropriately for the system. See the <a class="el" href="index.html#optimization">Optimization</a> section for more details.</li>
<li>A command packet buffer of type UINT32[264] that is the destination of tuning commands. <pre class="fragment"> #define PACKET_BUFFER_SIZE 264
 UINT32 AWE_Packet_Buffer[PACKET_BUFFER_SIZE];
</pre></li>
<li>A reply packet buffer of type UINT32[264] where the AWE Core places replies to tuning commands. <pre class="fragment"> UINT32 AWE_Packet_Buffer_Reply[PACKET_BUFFER_SIZE];
</pre> <b>Note: The standard packet size is 264. If a different packet size is needed, please contact DSPC Engineering. </b></li>
</ul>
<h3>Configuring the AWE Instance<a class="anchor" id="awe-configuring"></a></h3>
<p >Now that the required variables have been declared, the AWE Instance will be configured by assigning its members and pointers.</p>
<ul>
<li>First, ensure that the <a class="el" href="a00044.html#af3b70df7f9d672997e61999a024ba018">AWEInstance</a> is initialized to zeros. <br  />
</li>
<li>Assign the instanceID to 0. <pre class="fragment"> g_AWEInstance.instanceId = 0;
</pre></li>
<li>Assign the AWEInstance’s “pInputPin” and “pOutputPin” pointers to the input and output pin descriptors. <pre class="fragment"> g_AWEInstance.pInputPin = &amp;aweInputPin;
 g_AWEInstance.pOutputPin = &amp;aweOutputPin;
</pre></li>
<li>Assign the AWEInstance’s “pPacketBuffer” pointer to the command buffer that was declared above. <pre class="fragment"> g_AWEInstance.pPacketBuffer = AWE_Packet_Buffer;
</pre></li>
<li>Assign the AWEInstance’s “pReplyBuffer” pointer to the reply buffer. (Note that this can be assigned to the same buffer as the send buffer if a single buffer for send/reply is desired.) <pre class="fragment"> g_AWEInstance.pReplyBuffer = AWE_Packet_Buffer_Reply;
</pre></li>
<li>Assign the AWEInstance’s “packetBufferSize” member to 264. <pre class="fragment"> #define PACKET_BUFFER_SIZE 264
 g_AWEInstance.packetBufferSize = PACKET_BUFFER_SIZE;
</pre></li>
<li>Assign the “moduleDescriptorTable” pointer to the module descriptor table. <pre class="fragment"> g_AWEInstance.pModuleDescriptorTable = g_module_descriptor_table;
</pre></li>
<li>Assign the “numModules” member to the number of modules. This can be determined by taking the sizeof the module descriptor table and dividing it by the sizeof the first element of the module descriptor table. <pre class="fragment"> UINT32 module_descriptor_table_size = sizeof(g_module_descriptor_table) / sizeof(g_module_descriptor_table[0]); 
 g_AWEInstance.numModules = module_descriptor_table_size;
</pre></li>
<li>Assign the “numThreads” to the number of audio processing threads. See the <a class="el" href="index.html#multirate">Multi-Rate</a> section for more info. <pre class="fragment"> g_AWEInstance.numThreads = 2; //dual threaded, supports two blocksizes
</pre></li>
<li>Assign the “sampleRate” member to the fundamental sample rate of the system. <pre class="fragment"> g_AWEInstance.sampleRate = 48000.0f;
</pre></li>
<li>Assign the “fundamentalBlockSize” member to the fundamental block size of the system. This is typically the DMA block size. Every layout that is run on the system must have a block size that is a multiple of this fundamental block size. <pre class="fragment"> #define AWE_BLOCK_SIZE 32
 g_AWEInstance.fundamentalBlockSize = AWE_BLOCK_SIZE;
</pre></li>
<li>Assign the “pFlashFileSystem” member to 0 unless an Audio Weaver Flash File System will be implemented. <pre class="fragment"> g_AWEInstance.pFlashFileSystem = 0;
</pre></li>
<li>Assign the “fastHeapASize”, “slowHeapSize” and “fastHeapBSize” members to the heap sizes. <pre class="fragment"> g_AWEInstance.fastHeapASize = FAST_HEAP_A_SIZE;
 g_AWEInstance.fastHeapBSize = FAST_HEAP_B_SIZE;
 g_AWEInstance.slowHeapSize = SLOW_HEAP_SIZE;
</pre></li>
<li>Assign the “pFastHeapA”, “pSlowHeap” and “pFastHeapB” pointers to the heaps that were previously allocated. <pre class="fragment"> g_AWEInstance.pFastHeapA = g_FastHeapA;
 g_AWEInstance.pFastHeapB = g_FastHeapB;
 g_AWEInstance.pSlowHeap = g_SlowHeap;
</pre></li>
<li>Assign the “coreSpeed” and “profileSpeed” members to the CPU/profiling speed of the system. Only used for profiling displays in Audio Weaver tools. <pre class="fragment"> g_AWEInstance.coreSpeed = 10e6f;
 g_AWEInstance.profileSpeed = 10e6f;
</pre></li>
<li>Assign the “name”, this will be displayed in the AWE Server dialog as the name of the instance. Max length of 8 characters. <pre class="fragment"> g_AWEInstance.pName = “mytarget”;
</pre></li>
<li>Assign the "userVersion" member to be a UINT32 value. The value and meaning is entirely up to the integrator. <pre class="fragment"> //this example represents a date
 g_AWEInstance.userVersion = (UINT32) 06212019;
</pre></li>
<li>Assign callback pointers "cbAudioStart", "cbAudioStop". These are <b>optional callbacks</b> and user can define in the BSP to be notified by the AWE Core framework when the layout Design started or stoped. <pre class="fragment"> g_AWEInstance.cbAudioStart = &amp;usrCallbackAudioStart;
 g_AWEInstance.cbAudioStop = &amp;usrCallbackAudioStop;

 ///-----------------------------------------------------------------------------
 /// METHOD:  INT32 usrCallbackAudioStart(AWEInstance *pAWE)
 /// PURPOSE: Start audio processing callback
 ///-----------------------------------------------------------------------------
 INT32 usrCallbackAudioStart(AWEInstance *pAWE)
 {
     // Target specific configurations, if any, before starting the layout pump.
     // Like enabling audio IO interrupts etc.

     return 0;

 }   // End usrCallbackAudioStart

 ///-----------------------------------------------------------------------------
 /// METHOD:  INT32 usrCallbackAudioStop(AWEInstance *pAWE)
 /// PURPOSE: Stop audio processing callback
 ///-----------------------------------------------------------------------------
 INT32 usrCallbackAudioStop(AWEInstance *pAWE)
 {
     // Target specific configurations, if any, before destroying the layout.

     return 0;

 }   // End usrCallbackAudioStop
</pre></li>
<li>Assign callback pointer "cbCacheInvalidate". This is an <b>optional callback</b>, when defined, called from multiple places to invalidate cache. The FFSWrapper modules, IPCBuffer module, and the Multi Instance functionality in AWE Core all utilize this callback. It is the users responsibility to check if the provided address and length to be invalidated are in the cached region to avoid unnecessary overhead. Please note that this function called per block in some cases. <pre class="fragment"> g_AWEInstance.cbCacheInvalidate = &amp;usrCallbackCacheInvalidate;

 ///----------------------------------------------------------------------------
 /// METHOD:  usrCallbackCacheInvalidate
 /// PURPOSE: Invalidate cache region
 ///----------------------------------------------------------------------------
 INT32 usrCallbackCacheInvalidate(AWEInstance *pAWE, void* pStartAddr, UINT32 lengthInWords)
 {
    // Target specific cache invalidation logic.
    // Validate input argument pStartAddr. If it falls in the cached region then invalidate cache region with start address pStartAddr and end address (pStartAddr+length-1).

    return 0;

 }   // End usrCallbackCacheInvalidate
</pre> <h3>Initializing the IO Pins <a class="anchor" id="iopin_init"></a></h3>
</li>
</ul>
<p >The next step is to first initialize the IO Pins followed by initializing the AWE Instance using specific API functions. </p><h4>Initializing the IO Pins</h4>
<p >Simply call the <a class="el" href="a00044.html#a20d7c4aef91a7b0e190881efa67d15a7">awe_initPin()</a> function and pass it the input pin, the desired channel count (determined by audio HW), and an optional pin name.</p>
<p >define TWO_CHANNELS 2 int ret = awe_initPin(&amp;aweInputPin, TWO_CHANNELS, NULL);</p>
<p >The code above would initialize the input pin with 2 channels, and the default name.</p>
<p >Initializing the output pin is the same as the input pin, but the output pin is passed in. </p><pre class="fragment">#define SIX_CHANNELS 6
int ret = awe_initPin(&amp;aweOutputPin, SIX_CHANNELS, "outpin");
</pre><p> The code above would initialize the output pin with 6 channels with the name "outpin".</p>
<p >NOTE: multiple IO pins not supported. There can only be one input pin and one output pin. All API's that take the argument "pinIdx" will always pass in 0.</p>
<h3>Initializing the AWE Instance <a class="anchor" id="aweinstance_init"></a></h3>
<p >Next, initialize the AWE Instance by calling the <a class="el" href="a00044.html#ae4e7e278a5a4794714190415899d8022">awe_init()</a> function. <b>This must happen as the last initialization step.</b> If <a class="el" href="a00044.html#ae4e7e278a5a4794714190415899d8022">awe_init()</a> is called before the AWE Instance structure is configured or before the IO pins are initialized, the initialization will fail. </p><pre class="fragment">int ret = awe_init(&amp;g_AWEInstance);
</pre><p> The code above will initialize the AWE Instance.</p>
<h2>Setting up a Tuning Interface <a class="anchor" id="tuning-interface"></a></h2>
<p >The next step is to implement a <em>tuning interface</em> &ndash; arguably the most important component of a successful AWE Core integration as it provides essential debugging capabilities. The tuning interface communicates commands/replies to and from the AWE Instance. For example, these commands can instantiate a layout, or set and query the value of a module parameter. <br  />
</p>
<p >Different platforms will support different transport protocols for the tuning interface. AWE Server supports USB, TCP/IP (sockets), RS232, SPI, etc. Helper code is available to aid in the development of these different transport layers on the target. <b>It is the responsibility of the integrator to enable the transport protocol for the tuning commands to be passed to and from the platform.</b></p>
<p >Here are the basic steps for setting up and using a tuning interface with AWE Server.</p>
<ol type="1">
<li>Setup/test the desired transport layer between the board and the PC. Make sure that packets of length 264 words can be passed back and forth (echo). The protocol can be verified completely independently of AWE Core using some kind of simple application.</li>
<li>Once data can be passed, the tuning interface should be setup to receive commands from AWE Server. This process varies from protocol to protocol.</li>
<li>Once commands are received from AWE Server, they will need to be processed by the AWE Instance using <a class="el" href="a00044.html#ad4e9b6fa73ef4217ac60c80e7cb75b53">awe_packetProcess()</a>. Once a command is received from AWE Server, copy it into the <code>AWE_Packet_Buffer</code> and then call <code>awe_packetProcess(&amp;g_AWEInstance)</code> on the instance. Remember that this packet buffer has been registered with the AWE Instance, which is why the <code>awe_packetProcess(&amp;g_AWEInstance)</code> function does not need to take an argument to the packet buffer.</li>
<li>The <a class="el" href="a00044.html#ad4e9b6fa73ef4217ac60c80e7cb75b53">awe_packetProcess()</a> function will process the packet, and then generate a reply in the <code>AWEInstance.pReplyBuffer</code>. If the same buffer is used for both send and reply, the reply message will overwrite the original command.</li>
<li>Finally, the reply is sent back to the AWE Server over the transport layer. See the following pseudocode representation of the complete transaction. <pre class="fragment">int sizeOfPacket = 264;
readPacket(&amp;AWE_Packet_Buffer, sizeOfPacket);
awe_packetProcess(&amp;g_AWEInstance);
writePacket(&amp;AWE_Packet_Buffer_Reply, sizeOfPacket);
</pre> <h2>Real-time Audio <a class="anchor" id="rtaudio"></a></h2>
</li>
</ol>
<h3>RT Audio Introduction <a class="anchor" id="rtaudio_intro"></a></h3>
<p >The next step is to integrate real-time audio. AWE Core aside, real-time audio can be a tricky topic. Before attempting to integrate real-time audio into an AWE Core system, please ensure that the integrator has a basic understanding of digital audio and real-time audio processing. Here are some helpful links.</p>
<p ><a href="http://www.rossbencina.com/code">http://www.rossbencina.com/code</a></p>
<p ><a href="https://youtu.be/e1D5vCBWhdk">Giulio Moro - Assessing the stability of audio code for real time low latency embedded processing</a></p>
<h3>RealTime Audio Integration Steps <a class="anchor" id="rtaudio_steps"></a></h3>
<ol type="1">
<li><b>Verifying Audio HW IO with a Passthrough</b> Ensure that audio can be cleanly passed between input/output without the AWE Core involved in the signal path. A simple sine wave input into the system can often be the best audio source for this type of test, as any distortion or dropouts are more easily audible than with a more complex signal. This step is critical to ensure a high fidelity audio system, and can vary greatly from platform to platform. For instance, an embedded target might utilize the HW’s audio IO DMA, while Linux systems may use ALSA or something similar.</li>
<li><b>Determining Audio HW Settings and Configuring the AWE Instance.</b> These steps will describe how to set up the AWE Instance for RT Audio support.<ol type="a">
<li>Configure the sample rate and block size. For example, if the audio HW reads in samples at a block size of 32, then the AWE Instance’s fundamental blockSize should be set to 32. The block size of any layout loaded on the target must be a multiple of this fundamental block size. If the HW’s sampling rate is 44100.0, then the AWE Instance’s sampleRate should be set to 44100.0.</li>
<li>Determine the sample format of the audio HW. See the Audio Sample Formatting section below for more information on audio sample formatting.</li>
<li>Determine the Input/Output channel count of the audio HW. AWE Core needs to be able to import/export data for each available HW channel. For each available hardware input channel, the application will need to call <a class="el" href="a00044.html#a9e4bb98b017a47c1c1cad5e897c6390b">awe_audioImportSamples()</a>, and, likewise, <a class="el" href="a00044.html#ab2a5f4c7d4228495a3af02cad79b2ee7">awe_audioExportSamples()</a> will need to be called for each available hardware output channel. Using these channel-by-channel functions make it easy to aggregate multiple audio sources into a single, multi-channel input or output. Additionally, the Import and Export functions automatically handle what is referred to as 'channel matching'. Since AWE Core is designed to be flexible and Audio Weaver layouts are designed to be portable, the number of channels in a layout need not match the number of HW inputs and outputs in a system. If a layout has more I/O channels than the hardware channel count, then the Import and Export functions will automatically fill the input signal with additional zero'd channels, and will ignore any additional output channels. Similarly, if the layout loaded has fewer channels than the hardware channel count, then the Import and Export functions will ignore the additional HW input channels, and fill the additional HW output channels with zeros.</li>
</ol>
</li>
<li><b>The Realtime Audio Loop.</b> These steps describe what should happen inside the audio loop after configuration is complete.<ol type="a">
<li>In the audio loop, check to see that a valid layout is loaded and that audio has been started with the API calls <a class="el" href="a00044.html#aa14f1cef3b4579e3d0aac85fe9a7c9cd">awe_layoutIsValid()</a> and <a class="el" href="a00044.html#af4b5a0f5f9f869fb6e7ebeccfdd8fae3">awe_audioIsStarted()</a>.</li>
<li>Call <a class="el" href="a00044.html#a9e4bb98b017a47c1c1cad5e897c6390b">awe_audioImportSamples()</a> for each input channel and pass in the audio data from the audio HW.</li>
<li>Get the “layoutMask” from the <a class="el" href="a00044.html#ab8882c4641a4461678acfab526f61478">awe_audioGetPumpMask()</a> function. This will return a bit vector of the audio processing layouts that need to be pumped. The number of audio layouts to pump is determined by the number of clock-dividers (bufferup/down paths) in the .awb. The layoutMask bit vector should be bitwise AND'ed (&amp;) with <code>1 &lt;&lt; N</code>, for N=0:numThreads-1, to determine which layouts are ready to be pumped. Based on the system's capabilities, each layout should be pumped at it's own interrupt level/thread priority. See the <a class="el" href="index.html#multirate">Multi-Rate</a> section for more information.</li>
<li>Call <a class="el" href="a00044.html#a3e08c72e3bf11627e4fd87a99ebb6419">awe_audioPump()</a> for each layout as determined by the layoutMask above. The layout index will be the value of N from above.</li>
<li>Call <a class="el" href="a00044.html#ab2a5f4c7d4228495a3af02cad79b2ee7">awe_audioExportSamples()</a> for each output channel and pass in the audio HW’s output data.</li>
<li>Repeat.</li>
</ol>
</li>
</ol>
<h3>Audio Sample Formatting <a class="anchor" id="rtaudio_sample_formats"></a></h3>
<p >The data type of the input and output audio data is determined by the audio hardware. Typically, digital audio is represented as fixed point data in 16, 24, or 32 bit depth. The audio sample formats supported by AWE Core's <a class="el" href="a00044.html#a9e4bb98b017a47c1c1cad5e897c6390b">awe_audioImportSamples()</a> and <a class="el" href="a00044.html#ab2a5f4c7d4228495a3af02cad79b2ee7">awe_audioExportSamples()</a> functions, as defined in <a class="el" href="a00056.html#a2148c107244f027b63ea5fa4e55a582b">SampleType</a> in <a class="el" href="a00056.html">StandardDefs.h</a>, are:</p>
<ul>
<li><a class="el" href="a00056.html#aa902d2fa9a96414950faa1cd33d02af9af3eb7c4f84cd13fb1455fbeb00b8c236">Sample16bit</a> - Fixed point 16 bit audio data stored in 16 bit data type. Also known as Q15 format.</li>
<li><a class="el" href="a00056.html#aa902d2fa9a96414950faa1cd33d02af9afb3fcb8e832366ff800b86962fa90112">Sample24bit_low</a> - Fixed point 24 bit audio stored in 32 bit data type. Right justified, so the 24 bits of data are stored in the lowest 24 bits of the 32 bit word.</li>
<li><a class="el" href="a00056.html#aa902d2fa9a96414950faa1cd33d02af9a17b55cbfccd742cb31edbae658e9521a">Sample24bit_high</a> - Fixed point 24 bit audio stored in 32 bit data type. Left justified, so the 24 bits of data are stored in the highest 24 bits of the 32 bit word. If both right justified and left justified formatting is available on the hardware, then choose left justified (Sample24bit_high) for a slight performance improvement.</li>
<li><a class="el" href="a00056.html#aa902d2fa9a96414950faa1cd33d02af9a8267a816f0e5d656471666befe047de3">Sample32bit</a> - Fixed point 32 bit audio data. Also known as Q31 format. This data is passed directly to the signal processing chain without conversion.</li>
</ul>
<p >Internally, all inputs and outputs to Audio Weaver layouts are of type <a class="el" href="a00056.html#aa902d2fa9a96414950faa1cd33d02af9a8267a816f0e5d656471666befe047de3">Sample32bit</a>, also referred to as fract32 within a layout. This is done to guarantee portability of any signal processing layout to any target system, regardless of the hardware's native audio data type. The <a class="el" href="a00044.html#a9e4bb98b017a47c1c1cad5e897c6390b">awe_audioImportSamples()</a> and <a class="el" href="a00044.html#ab2a5f4c7d4228495a3af02cad79b2ee7">awe_audioExportSamples()</a> functions will convert to and from the Sample32bit data as needed based on the integrator's supplied <a class="el" href="a00056.html#aa902d2fa9a96414950faa1cd33d02af9">_SampleType</a> argument. If the target's native audio sample formatting is not one of those listed above, then the integrator will have to manually convert the data to one of the supported types before using the import and export functions.</p>
<p >Since some common target systems natively support floating point audio, helper functions are provided to convert between float&lt;--&gt;fract32 in AWECoreUtils.c, which is provided in the AWE Core package. Add AWECoreUtils.c to the build project to access the sample-by-sample conversion functions <a class="el" href="a00041.html#a45fc7eb0345371558e5a7c64a49d37dc">float_to_fract32</a> and <a class="el" href="a00041.html#aba0c59d3b316b3e0c6b461e82157f33c">fract32_to_float</a>. See the API in doc <a class="el" href="a00041.html">AWECoreUtils.h</a> for more info.</p>
<h3>Multi-Rate Processing<a class="anchor" id="multirate"></a></h3>
<p >The AWE Core allows audio to be processed at multiple block rates. For example, consider a system with two processing paths: one that processes time-domain data in blocks of 32 samples and another that processes frequency-domain data in blocks of 64 samples but at 1/2 the rate of the time-domain path. Such a system is shown in the figure below. It uses BufferUp and BufferDown modules to connect the different block size domains. These modules effectively partition the layout into 2 sub-layouts operating at different block rates.</p>
<p ><img src="../images/multirate-layout.png" alt="Multi-Rate Layout" class="inline"/></p>
<p >The two paths are executed at different rates and AWE Core’s <a class="el" href="a00044.html#ab8882c4641a4461678acfab526f61478">awe_audioGetPumpMask()</a> API call provides a mechanism to determine when the processing for each path should be initiated. Consider the following pseudocode: <br  />
 </p><pre class="fragment">layoutMask= awe_audioGetPumpMask(&amp;g_AWEInstance);

if (layoutMask &amp; 0x1) raise(AWEProcess_HiPrio);
if (layoutMask &amp; 0x2) raise(AWEProcess_LowPrio);

AWEProcess_HiPrio() 
{ 
    awe_audioPump(&amp;g_AWEInstance, 0); // small block size path
}
AWEProcess_LowPrio()
{ 
    awe_audioPump(&amp;g_AWEInstance, 1); // large block size path
}
</pre><p> This code tests which sub-layouts have accumulated enough data to execute. The layoutMask variable contains a 1 in each bit position corresponding to sub-layout that is ready to execute. For example, if layouts 0 and 1 are ready to execute, layoutMask would be 0x00000003.</p>
<p >Lower numbered sub-layouts correspond to smaller block sizes. In the pseudo-code, a signal is raised for each sub-layout that is ready to be pumped.</p>
<h4>High Level OS Profiling on Multi Core Devices</h4>
<p >Profiling designs on high-level OSes is challenging because layout threads may run on any available core at any given time. An OS-level mechanism to lock a particular thread to a certain core may be available. If so, one can notify AWECore that a layout thread will run on a specific core, and more accurate profiling will be shown in AWE Server. These functions are <a class="el" href="a00044.html#a094bfa13c7a61ecee94cdf87e4c88390">awe_fwSetLayoutCoreAffinity()</a> and <a class="el" href="a00044.html#abef98cd8c780d02cb9d88559cb28a390">awe_fwGetLayoutCoreAffinity()</a>. By default, all layouts are assumed to run on core 0.</p>
<h3>Multi-Rate Scheduling<a class="anchor" id="multirate-scheduling"></a></h3>
<p >Real-time constraints dictate that if the 64 sample sub-layout is executed in the same context as the 32 sample sub-layout, both will need to complete processing before the next block of 32 samples arrives or real-time will be broken. This imposes an unnecessarily strict constraint on the 64 sample sub-layout &ndash; its processing need only be completed before the next block of 64 samples is accumulated. Thus, its processing time can, in principle, be spread over 2 of the 32 sample block times without breaking real-time. In practice, this is achieved by executing the two sub-layouts in separate contexts. The sub-layout with the shorter block size should have higher priority so that it can preempt the processing of the sub-layout with the longer block size. In this way, the real time constraints of each sub-layout can be accommodated. The following figure shows the timing for this example:</p>
<p ><img src="../images/multirate-threading.png" alt="Multi-Rate Threading Model" class="inline"/></p>
<h3>Multi-Instance Scheduling<a class="anchor" id="multi-instance-scheduling"></a></h3>
<p >In the multi-instance environment where instance 0 is the master with interface to audio IO peripherals, it's common to have bigger layout block size on secondary instances then the layout block size on instance 0. In this situation, it's not a good practice to signal secondary instances at the fundamental block rate. To avoid unnecessary overhead with signalling secondary instances at higher block rate, user must call <a class="el" href="a00044.html#acb3df1d67abff15df3f81accf213a379">awe_audioIsReadyToPumpMulti()</a> API and if it returns TRUE then signal the secondary instance.</p>
<ul>
<li>If there two instances, call <a class="el" href="a00044.html#acb3df1d67abff15df3f81accf213a379">awe_audioIsReadyToPumpMulti()</a> to check if the second instance is ready to pump as <pre class="fragment"> if (awe_audioIsReadyToPumpMulti(&amp;g_AWEInstance, 1))
 {
     // Signal secondary instance to check for the pump mask, through either raise() or any other option depending on the target
 }
</pre></li>
<li>Call the above function, as many times as the slave instances (with ID &gt; 0) and signal the corresponding instance.</li>
<li>When this function is called with instance id 0 or invalid ID, it always returns FALSE.</li>
</ul>
<h3>Multi-Rate and Multi-Instance Profiling<a class="anchor" id="multirate-multiinstance-profiling"></a></h3>
<p >In a multi rate processing with different priorities of each processing thread, it's quite common that the low priority thread processing is preempted by the high priority thread processing which affects the profiling of low priority thread processing due to the continuous clock counter. By default, AWE Core corrects the overhead by the high priority thread processing due to preemption. Currently the preemption overhead correction is supported on all the platforms except Windows (WIN32) and Linux.</p>
<p >In a system with multiple AWE Instances in the same core, user must call <a class="el" href="a00044.html#a5fd23e753a1360b0ec5112102ea5536f">awe_setInstancesInfo()</a> API to enable the preemption overhead correction in profiling. Call this API as the last step in init sequence after all AWE Instances are configured and initialized.</p>
<ul>
<li>Declare a global array of AWEInstance pointers with size for number of AWE Instances in a single core <pre class="fragment"> AWEInstance *g_pInstances[NUM_AWE_INSTANCES];
</pre></li>
<li>Initialize the array with each instance pointer <pre class="fragment"> for (int i = 0; i &lt; NUM_AWE_INSTANCES; i++)
 {
     g_pInstances[i] = &amp;g_AWEInstance[i];
 }
</pre></li>
<li>Call <a class="el" href="a00044.html#a5fd23e753a1360b0ec5112102ea5536f">awe_setInstancesInfo()</a> API to initialize overhead correction in the profiling <pre class="fragment"> awe_setInstancesInfo(g_pInstances, NUM_AWE_INSTANCES);
</pre> <h3>Preemption Overhead Outside of the Layout<a class="anchor" id="profiling-correction-by-external-events"></a></h3>
</li>
</ul>
<p >In a multi-rate or multi-instance systems, when the low priority layout processing is preempted by high priority layout processing, the profiling overhead of the high priority layout processing is corrected by default within the AWE Core framework. To include overhead due to external events like DMA ISR, call <a class="el" href="a00044.html#acc6569fd8a744cb20232e606643dfc54">awe_audioStartPreemption()</a> and <a class="el" href="a00044.html#ac05894753bc9b9f318d9a95218a03e94">awe_audioEndPreemption</a> as explained below.</p>
<ul>
<li>DMA ISR without low latency audio pump: <pre class="fragment"> DMA ISR()
 {
     UINT32 start_time;
     INT32 coreAffinity = 0;

     // For embedded targets, default core affinity is 0 in AWE Core.
     // For other targets like Linux based, get the core affinity from which this function is called.

     // Call the start preemption API to get the start time stamp
     start_time = awe_audioStartPreemption(&amp;g_AWEInstance, coreAffinity);

     // All the audio import calls here
     // All the audio export calls here
     // Get pump mask and other code

     // Call the end preemption API to include this ISR overhead in any low priority active layout(s)
     awe_audioEndPreemption(&amp;g_AWEInstance, start_time, coreAffinity);
 }
</pre></li>
</ul>
<p >DMA ISR with low latency audio pump: </p><pre class="fragment">  DMA ISR()
  {
      UINT32 start_time;
      INT32 coreAffinity = 0;

      // For embedded targets, default core affinity is 0 in AWE Core.
      // For other targets like Linux based, get the core affinity from which this function is called.

      // Call the start preemption API to get the start time stamp
      start_time = awe_audioStartPreemption(&amp;g_AWEInstance, coreAffinity);

      // All the audio import calls here
      // Get pump mask and other code

      // Call the end preemption API to include overhead by import calls in any low priority active layout(s)
      awe_audioEndPreemption(&amp;g_AWEInstance, start_time, coreAffinity);

      // Call the low latency audio pump. Overhead due to this pump call in any low priority active layout(s) is corrected by the AWE Core framework
      awe_audioPump(&amp;g_AWEInstance, 0);

      // Call the start preemption API to get the start time stamp, after low latency pump call to include overhead due to export calls
      start_time = awe_audioStartPreemption(&amp;g_AWEInstance, coreAffinity);

      // All the audio export calls here

      // Call the end preemption API to include overhead by export calls in any low priority active layout(s)
      awe_audioEndPreemption(&amp;g_AWEInstance, start_time, coreAffinity);
  }
</pre><ul>
<li>To correct overhead due to multiple external events (for example, DMA ISR and UART IST in baremetal BSP), user has to call the above methods in each event and additional handling needs to be done in one os some of the external event handling routines. Following is the example use case correcting overhead due to DMA ISR and UART ISR in typical baremetal BSP. <pre class="fragment"> // Global variable which counts overhead by the high priority interrupt (UART ISR in this case)
 UINT32 uartOverhead = 0;

 DMA ISR()
 {
     UINT32 start_time;
     INT32 coreAffinity = 0;

     // For embedded targets, default core affinity is 0 in AWE Core.
     // For other targets like Linux based, get the core affinity from which this function is called.

     // Clear the high priority event overhead at the beginning
     uartOverhead = 0;

     // Call the start preemption API to get the start time stamp
     start_time = awe_audioStartPreemption(&amp;g_AWEInstance, coreAffinity);

     // All the audio import calls here
     // All the audio export calls here
     // Get pump mask and other code

     // Call the end preemption API to include this ISR overhead in any low priority active layout(s)
     // Consider high priority event overhead if it happened from this ISR
     awe_audioEndPreemption(&amp;g_AWEInstance, start_time + uartOverhead, coreAffinity);
 }

 UART ISR()
 {
     UINT32 start_time;
     INT32 coreAffinity = 0;

     // For embedded targets, default core affinity is 0 in AWE Core.
     // For other targets like Linux based, get the core affinity from which this function is called.

     // Call the start preemption API to get the start time stamp
     start_time = awe_audioStartPreemption(&amp;g_AWEInstance, coreAffinity);

     // UART packets handling

     // Call the end preemption API to include this ISR overhead in any low priority active layout(s)
     // Accumulate the overhead for the low priority events (DMA ISR in this case) to address recursive preemptions in the same DMA block
     uartOverhead += awe_audioEndPreemption(&amp;g_AWEInstance, start_time, coreAffinity);
 }
</pre> <h2>Deferred Processing <a class="anchor" id="deferred-processing"></a></h2>
</li>
</ul>
<p >There are certain AWE modules that need to perform time consuming calculations, for example when the cutoff frequency of a Second Order Filter module is changed, the filter coefficients need to be recalculated. Performing these calculations in the audio processing context can cause it to overrun. To address this issue, certain modules defer those calculations until the firmware calls <code>awe_deferredSetCall()</code>.</p>
<p ><em>Note: For module authors, the <code>awe_deferredSetCall()</code> function calls the module's Set function with a mask of 0xFFFFFF00.</em></p>
<p >An integrator can check for any required deferred processing using the return value of <a class="el" href="a00044.html#a3e08c72e3bf11627e4fd87a99ebb6419">awe_audioPump()</a>, which will return <code>TRUE</code> if any deferred processing is pending. If deferred processing is needed, then call <a class="el" href="a00044.html#a2f78d537ec23c5222d4533de286f6349">awe_deferredSetCall()</a> at a priority that is lower than the audio processing. <a class="el" href="a00044.html#a2f78d537ec23c5222d4533de286f6349">awe_deferredSetCall()</a> performs deferred processing for a single module, and returns <code>TRUE</code> if there is more deferred processing that is pending. Thus it should be called repeatedly until it returns <code>FALSE</code>. <br  />
 </p><pre class="fragment">//g_bDeferredProcessingRequired is returned by awe_audioPump()

if (g_bDeferredProcessingRequired || bMoreProcessingRequired)
{
    g_bDeferredProcessingRequired = FALSE;
    bMoreProcessingRequired = awe_deferredSetCall(&amp;g_AWEInstance);
}
</pre> <h2>Standalone Operation <a class="anchor" id="standalone-operation"></a></h2>
<p >At this point, the integrator should be able to load a layout from Audio Weaver Designer and run it on the target via the Tuning Interface. Once a Layout in Designer has been completed, it is easy to switch to stand-alone operation. Simply ask Audio Weaver to "Generate Target Files", and the Layout's configuration-data will be generated as a C array to be compiled into the system.</p>
<h3>Loading from an Array <a class="anchor" id="load-array"></a></h3>
<p >From the viewpoint of AWE Core, the signal processing layout is described by a data array of binary Audio Weaver commands. This command array is generated by Audio Weaver Designer using the Tools/Generate Target Files menu item and enabling the [BaseName]_initAWB checkbox. The layout is loaded into an AWE Core instance by making a call to <a class="el" href="a00044.html#aab1dea09d71a8da65f245174da6d594e">awe_loadAWBfromArray</a> with the command array, its size in 32-bit words, and the AWEInstance as arguments. If an error occurs during loading, then the offset of the offending AWB command is returned to the pPos argument. </p><pre class="fragment">INT32 err = awe_loadAWBfromArray (&amp;g_AWEInstance, pCommands,arraySize, &amp;nErrOffset);
if (err)
{
    // report the error
    printf(“error code %u due to command at position %u\n”, err, nErrOffset);
    // handle the error
    ...
}
</pre><p> <a class="el" href="a00044.html#aab1dea09d71a8da65f245174da6d594e">awe_loadAWBfromArray()</a> will load the entire array of commands and process them locally on the AWE Instance. If an array of commands needs to be loaded on a remote instance, it can be loaded command by command with the <a class="el" href="a00041.html#a4eb47b8693cd4a3bb9c7b53f772fb4c1">awe_getNextAWBCmd()</a> helper function in <a class="el" href="a00041.html">AWECoreUtils.h</a>. Each command is parsed so that they can be routed to the remote instance.</p>
<h2>AWE Core Scheduling and Priority <a class="anchor" id="scheduling-priority"></a></h2>
<p >All priority and interrupt issues are managed outside of the AWE Core by the firmware integrator since the AWE Core has no knowledge of the supporting processing environment it is being integrated into. The following processing context may be implemented using interrupt handlers or using OS threads/tasks. The main requirement is that the processing context is implemented at different preemptible priority levels.</p>
<p >A basic Audio Weaver platform has a minimum of five priority levels of processing. From highest priority to lowest priority:</p>
<ul>
<li><b>Priority 1: Tuning Communication I/O</b> <b>Task:</b> Receives/sends data over the communication transport layer, for example RS232, USB, SPI, or Ethernet. <em>Note: Tuning commands are not processed in this context; data is simply moved into and out of the tuning packet buffer.</em> <b>Action</b>: Insert received data into the tuning packet buffer or send reply data from tuning packet buffer. When a complete packet has been received, signal the low priority idle task to process it.</li>
<li><b>Priority 2: Audio I/O</b> <b>Task:</b> Complete audio frame has been received. Blocks of audio samples are exchanged between DMA buffers and the AWE Core input and output buffers. <b>Action:</b> Copy new audio samples into AWE layout input buffers copy latest AWE layout processed audio samples to output buffers if enough audio samples are available trigger Priority 3 and/or Priority 4 tasks to perform signal processing.</li>
<li><b>Priority 3: Audio Processing</b> <b>Task:</b> Process one AWE layout-defined frame of audio samples. <b>Action:</b> At this priority level, the active signal processing layout is processed with <a class="el" href="a00044.html#a3e08c72e3bf11627e4fd87a99ebb6419">awe_audioPump()</a>.</li>
<li><b>Priority 4: Lower Priority Audio Processing (multi-rate)</b> <b>Task:</b> Process one larger AWE layout-defined frame of audio samples. <b>Action:</b> At this priority level, longer duration signal processing is initiated with <a class="el" href="a00044.html#a3e08c72e3bf11627e4fd87a99ebb6419">awe_audioPump()</a> but at a lower priority than the normal audio processing above.</li>
<li><b>Priority 5: Background Processing</b> <b>Task:</b> In background / idle loop context, non-real-time tasks are processed. This includes the processing of tuning commands, deferred processing, and any Control Interface processing. <b>Action:</b><ul>
<li>Process a received tuning command.</li>
<li>Process any deferred processing needed for a single module.</li>
<li>Perform any needed interaction with the layout from the firmware.</li>
</ul>
</li>
</ul>
<p >These three actions <b>must be atomic</b> to avoid the possibility of race conditions due to concurrent access of resources. </p><h2>Setting up a Control Interface <a class="anchor" id="ctrl-interface"></a></h2>
<h3>Control Interface Overview <a class="anchor" id="ctrl-interface-overview"></a></h3>
<p >A control interface lets the system interact with modules in the running layout directly from the firmware. To access the layout from the API, use Designer to generate a control-interface header file for the layout. Then, use the following API calls define the functionality of the control interface:</p>
<p >Get/set a value of a module: <a class="el" href="a00044.html#aa53e394306aef852b52305bf638235bb">awe_ctrlGetValue()</a> and <a class="el" href="a00044.html#a292350a96704f17e8cd1ba3607b0d702">awe_ctrlSetValue()</a> </p><pre class="fragment">INT32 awe_ctrlGetValue(const AWEInstance *pAWE, UINT32 handle, void *value, INT32 arrayOffset, UINT32 length)
INT32 awe_ctrlSetValue(const AWEInstance *pAWE, UINT32 handle, const void *value, INT32 arrayOffset, UINT32 length)
</pre><p> Get/Set the status of a module (bypassed, active, inactive, muted): <a class="el" href="a00044.html#aa3d5b1802114a32413c9c6482eb995b0">awe_ctrlSetStatus()</a> and <a class="el" href="a00044.html#a2693d881f364d79d8f486ea8c884d09b">awe_ctrlGetStatus()</a> </p><pre class="fragment">INT32 awe_ctrlSetStatus(const AWEInstance *pAWE, UINT32 handle, UINT32 status)
INT32 awe_ctrlGetStatus(const AWEInstance *pAWE, UINT32 handle, UINT32 *status)
</pre><p> Check if a module exists, and if so return its ClassID: <a class="el" href="a00044.html#aeb38b521f683f62c7249a609f4a5bc4e">awe_ctrlGetModuleClass()</a> </p><pre class="fragment">INT32 awe_ctrlGetModuleClass(const AWEInstance *pAWE, UINT32 handle, UINT32 *pClassID)
</pre><p> The following functions provide finer grained control over how module variables get set and are for advanced users: <a class="el" href="a00044.html#ae72dedbda062001d3b53369abd398c85">awe_ctrlSetValueMask()</a> and <a class="el" href="a00044.html#ae46f5a02752fa2ea9fb26691f3ad744d">awe_ctrlGetValueMask()</a> </p><pre class="fragment">INT32 awe_ctrlSetValueMask(const AWEInstance *pAWE, UINT32 handle, const void *value, INT32 arrayOffset, UINT32 length, UINT32 mask)
INT32 awe_ctrlGetValueMask(const AWEInstance *pAWE, UINT32 handle, void *value, INT32 arrayOffset, UINT32 length, UINT32 mask)
</pre><h3>Control Interface Steps <a class="anchor" id="ctrl-interface-steps"></a></h3>
<p >To access a module and control it via the Control Interface,</p>
<ul>
<li>Create the desired layout. In the build tab of a module, assign an objectID to the module's that will be accessed. The objectID must be a value between 30000-32767.</li>
<li>Generate a ControlInterface.h header file from the layout with Tools-&gt;Generate Target Files. Make sure the [BaseName]_ControlInterface.h box is checked.</li>
<li>Include the generated [BaseName]_ControlInterface.h file in the AWE Core integration. This file will contain all of the define's required to use the API's control functions.</li>
<li>Check if the module exists and is of the right class with <a class="el" href="a00044.html#aeb38b521f683f62c7249a609f4a5bc4e">awe_ctrlGetModuleClass()</a>.</li>
<li>Use one of the awe_ctrl functions to set/get something about a module.<ul>
<li>The <code>handle, length</code> arguments will all be defined in the [BaseName]_ControlInterface.h file that was generated. See the <a class="el" href="a00044.html">API Doc</a> for details about the control functions arguments/return values.</li>
</ul>
</li>
<li>Check the return value for errors and handle appropriately.</li>
</ul>
<p >See the following example. </p><pre class="fragment">    // Does the current AWE model have a SinkInt module with this control object ID?
    if (awe_ctrlGetModuleClass(&amp;g_AWEInstance, AWE_SinkInt1_value_HANDLE, &amp;classID) == OBJECT_FOUND)
    {
        // Check that module assigned this object ID is of module class SinkInt
        if (classID == AWE_SinkInt1_classID)
        {
            // SinkInt module (value is an array)
            awe_ctrlGetValue(&amp;g_AWEInstance, AWE_SinkInt1_value_HANDLE, &amp;nValue, 0, 1);
        }
    }
</pre> <h2>Optimization <a class="anchor" id="optimization"></a></h2>
<p >The AWE Core can be optimized for a system for heap space and for image size.</p>
<h3>Heap Sizing and Placement <a class="anchor" id="heap-sizing"></a></h3>
<p >In a typical workflow, the integrator would decide on heap size/placement for development and finally optimized for production.</p>
<p >To decide on heap size/placement for board bring-up, set all three heaps to some small number of 1K word blocks say (1024 * 5). When the BSP is fully developed inspect the memory map to determine how much free space is available in the memory sections that have been assigned to the heaps. Then adjust the heap space to use as much of this memory as is practical. A typical assignment of heap might be to assign processor “tightly coupled memory” to fast heap A, processor RAM to fast heap B, and off-chip SDRAM to the slow heap.</p>
<p >Audio Weaver Designer can also generate the absolute smallest heap sizes needed for a specific layout via Tools-&gt;Generate Target Files and selecting [BaseName]_HeapSize.h. This can greatly reduce the memory footprint and aid in optimizing an AWE Core integration.</p>
<h3>Module List Optimization <a class="anchor" id="modulelist-optimization"></a></h3>
<p >The ModuleList.h file that is delivered with AWE Core contains a large set of modules. This is convenient during development to provide a large selection of modules with which to design layouts. To optimize for a specific layout at production time, Audio Weaver Designer can generate a ModuleList.h with only the modules used by that layout using Tools-&gt;Generate Target Files-&gt;[BaseName]_ModuleList.h. Since most modern linkers will only link those modules referenced, this will significantly reduce the image size.</p>
<h2>Multiple AWE Instances <a class="anchor" id="multi-awe-instance"></a></h2>
<h3>Multiple AWE Instances Introduction <a class="anchor" id="multi-awe-instance-intro"></a></h3>
<p >AWE Core target systems can contain multiple AWE Instances. This is useful on a platform with multiple cores when a system needs to do signal processing on each core, or if separate instances are needed for dedicated signal processing tasks.</p>
<p >AWE Core supports two methods of implementing multiple AWE Instances on a target system. Both methods support multiples AWE Instances on a single core, or across multiple cores on a single SOC.</p>
<ol type="1">
<li><b>Multi Instance (Recommended):</b> Depends on a 'shared heap' approach. This heap is provided by the user application and is allocated in a shared region of memory accessible to all AWE Core instances on a target. AWE Core handles all tuning packet handling and audio data routing between instances using this shared memory. <br  />
 With this approach, a single layout (AWD file) is created and can be distributed across all AWE Core instances. The 'IPCBuffer' module in Designer is used to route audio between AWE Core instances and to define the target instance for the downstream modules in the layout.. <br  />
</li>
</ol>
<p ><em><b>Note: The Multi Instance feature is currently released as a beta feature, and may change in incompatible ways in future releases.</b></em></p>
<ol type="1">
<li><b>Multi Canvas:</b> Each AWE Core instance is independently connected to Designer. The user is responsible for routing tuning packets and audio to each instance using their own IPC protocol. Each AWE Core instance has its own independent layout (AWD file). This method might be preferable for those who wish to split signal processing designs among teams, and also results in smaller .awd design files.</li>
</ol>
<p >Before setting up a multi instance tuning interface, we recommend implementing a single instance tuning interface. This will solidify the theory of operations and allow for easier understanding of the multi instance model.</p>
<p >AWE Core packets always contain a prefixed address called an 'instanceID'. On a single instance system, this instanceID is always 0. However, when developing a multi instance system, commands can be addressed to different instanceID's.</p>
<p >It is important to note that there is normally only one tuning interface between Server and the system. That single tuning interface will receive the packets for all instances and the BSP integrator must route them to the correct instance.</p>
<p ><b>(Multi Instance only):</b> The instanceID of an AWE command is determined by the instanceID of a module/wire in the design. The instanceID is a propagatable field, and can be modified using the 'IPCBuffer' module, or, for a source module, by setting the clockDivider field in the build tab of the module properties. The syntax to set the clockDivider field is &lt;clockDivider (#)&gt;&lt;threadThead (letter)&gt;&lt;instanceID (#)&gt;, so '2B3' will run the source module with clockDivider of 2, on thread B of instance 3. The 'IPCBuffer' module exists to take one or more input wires of data that exists on one instanceId, and send it to another user-specified instanceId. <b>(Multi Canvas only):</b> When using Designer, the instanceID of an AWE command is determined by which instance is selected in the dropdown window of Designer.</p>
<h3>Multi Instance Guide <a class="anchor" id="multi-instance-guide"></a></h3>
<p >Utilizing multi instance AWE Core requires these steps:</p>
<ol type="1">
<li>Allocate a shared heap memory space in a memory region accessible to all AWE Core instances. If this shared memory region is cached, see the cbCacheInvalidate callback function in the <a class="el" href="a00044.html#af3b70df7f9d672997e61999a024ba018">AWEInstance</a> structure. Attach this shared memory space, along with its size, to each AWE Core instance using the following <a class="el" href="a00044.html#af3b70df7f9d672997e61999a024ba018">AWEInstance</a> struct members: <pre class="fragment">/** The shared heap. */
volatile UINT32 *pSharedHeap;

/** The shared heap size. */
UINT32 sharedHeapSize;
</pre></li>
<li>Allocate the tuning packet buffer in a shared memory region accessible to all AWE Core instances. Initialize the reply buffer pointer to the same memory region as the packet buffer. (See the Single Instance Tuning Interface Section for more details)</li>
<li>Provide a unique instanceId to each AWE Core instance, with instanceId 0 reserved for the AWE Core instance that is the primary audio processing instance. The primary audio processing instance is the one that interacts with the audio input and output devices, and is the only instance that should call <a class="el" href="a00044.html#a20d7c4aef91a7b0e190881efa67d15a7">awe_initPin()</a>. The instanceId numbering scheme follows a linearly incrementing digit starting from 0 (e.g. 0, 1, 2, 3...). Note that if there is a tuning only instance that does no audio processing and only forwards packets to processing instances, then both the tuning only instance and the primary audio processing instance must have instanceId equal to 0. This tuning only instance must be initialized with <a class="el" href="a00044.html#ae4e7e278a5a4794714190415899d8022">awe_init</a> for awe_loadAWB* API's to function correctly.</li>
<li>Set the numProcessingInstances member of each AWE Core instance to the total number of AWE Core instances on the target system. For example, if the target system has two AWE Core instances (instanceId: 0 and instanceId: 1), then the numProcessingInstances member of each AWE Core instance should be set to 2. Tuning only instances do not contribute to this number. <pre class="fragment">/** The number of audio processing instances of AWECore configured on a single target */
UINT32 numProcessingInstances;
</pre></li>
<li>Using a global software interrupt accessible to all AWE Core instances, trigger each instance to check their pump mask and pump. This trigger is required to be synchronous to the audio peripheral data passed in/out of AWE Core instance 0. (See RealTime Audio Integration Steps for more details on mask reading and pumping audio)</li>
<li>Process packet buffer data using the multi instance packet process API <a class="el" href="a00044.html#a2d5438a02407ecb829c58faa4b2610f8">awe_packetProcessMulti()</a>. For the tuning master instance, the API is called once a complete packet is received. For non-tuning instances, the API is polled in a low-priority task.</li>
</ol>
<p >For more details on how to implement multi instance AWE Core, including pseudocode related to all necessary implementation details, read the Multi-Instance AWE Core Integration Guide found at (<a href="https://documentation.dspconcepts.com/awe-designer/latest-version/application-notes">https://documentation.dspconcepts.com/awe-designer/latest-version/application-notes</a>), or see the example file <a class="el" href="a00084.html">LinuxAppMulti.c</a>.</p>
<h3>Multi Canvas Guide <a class="anchor" id="multi-canvas-guide"></a></h3>
<h4>Multi Canvas Tuning Interface Setup <a class="anchor" id="multi-canvas-tuning-setup"></a></h4>
<h4>Basic Overview of Multi Canvas Integration Steps</h4>
<p >Integrating a multi canvas AWE Core system can be broken into the following basic steps. This assumes that the integrator is able to implement a single instance tuning interface.</p>
<ol type="1">
<li>Setup and initialize the multiple AWE Instances with appropriate instanceID’s.</li>
<li>Setup a tuning interface and tell Server how many instances there are. Do this by generating a reply to the PFID_GetCores2 AWE command sent from AWE Server.</li>
<li>Route the packets to the correct instance based on the packet’s instanceID prefix.</li>
<li>Send the replies back to Server.</li>
</ol>
<h4>Detailed Multi-Canvas Integration Steps</h4>
<ol type="1">
<li>Allocate/initialize the multiple AWE Instances with their instanceIDs. The instanceID is stored in the high order 4 bits of an 8 bit word. Therefore the first instance must always be 0, and the following cores will increment by 16. <b>IMPORTANT: InstanceID’s should always increment by 16. So the instanceID’s for a 2 instance system would be 0, 16. For a 3 instance system, 0, 16, 32. Etc... </b></li>
<li>Declare an instance table array as a UINT32[numInstances], where the elements are the instanceID’s of the AWE instance’s that were just initialized. <pre class="fragment">//the following instance table represents a two-instance system.
UINT32 numInstances = 2;
UINT32 instanceIDs[numInstances] = { 0, 16 };
</pre></li>
<li>Implement a tuning interface to pass AWE commands between AWE Server and the target (See the Single Instance Tuning Interface Section).</li>
<li>When multi canvas is to be supported, the BSP author will setup the tuning interface to listen for the AWE Command “PFID_GetCores2” (use the PACKET_OPCODE macro and the enum in ProxyIDs.h to determine this command). When this command is received, use the GenerateInstanceTableReply function in AWECoreUtils to generate a reply to the PFID_GetCores2 command. Send the instance table reply back to the Server over the tuning interface. Now AWE Server knows how many instances there are in the system, and can create a dropdown list of the instances in AWE Server and Designer.</li>
</ol>
<pre class="fragment">if (opcode == PFID_GetCores2)
{
    GenerateInstanceTableReply(AWE_Packet_Buffer_Reply, numInstances, instanceIDs);
    writePacketToServer(AWE_Packet_Buffer_Reply);
}
</pre><ol type="1">
<li>Implement a packet router. The tuning interface must be able to send/receive packets from all instances. The packet router will take a packet from the Server, strip off its instanceID (use the macro PACKET_INSTANCEID), and then route the command to the appropriate instance.</li>
</ol>
<h4>Multi Canvas Pseudocode Examples <a class="anchor" id="multi-canvas-pseudocode"></a></h4>
<p >The following pseudocode example is for a chip with two signal processing AWE Instances with the first AWE Instance providing the tuning interface. </p><pre class="fragment">TuningInterface()
{
    AWE_Packet_Buffer = receivePacketFromServer();

    if (PACKET_OPCODE(AWE_PACKET_BUFFER) == PFID_GetCores2)
    {
        *AWE_Packet_Buffer = *GenerateInstanceTableReply(AWE_Packet_Buffer, numInstances, instanceIDs);
        writePacketToServer(AWE_Packet_Buffer);
    }
    else if (PACKET_INSTANCEID(AWE_Packet_Buffer) == 0)
    {
        awe_packetProcess(&amp;AWEInstance0);
        writeReplyToServer();
    }

    else if (PACKET_INSTANCEID(AWE_Packet_Buffer) == 16)
    {
        sendToInstance16();
        //command is processed on instance 16
        readReplyFromInstance16();
        writeReplyToServer();
    }
}
</pre><p> Below is a pseudocode example of a multi-canvas tuning interface that is implemented on an MCU that has no knowledge of the AWE Core instances. The system has two AWE instances on separate processors, with IDs of 0 and 16. </p><pre class="fragment">TuningInterface()
{
    Tuning_PacketBuffer= receivePacketFromServer();

    if (PACKET_OPCODE(Tuning_PacketBuffer) == PFID_GetCores2)
    {
        GenerateInstanceTableReply(Tuning_PacketBuffer, numInstances, instanceIDs);
        writePacketToServer(Tuning_PacketBuffer);
    }
    else if (PACKET_INSTANCEID(Tuning_PacketBuffer) == 0)
    {
        sendPacketToInstance0(Tuning_PacketBuffer);
        //Instance 1 gets packet and calls awe_packetProcess
        receiveReplyPacketFromInstance0();
        writeReplyToServer();
    }

    else if (PACKET_INSTANCEID(AWE_Packet_Buffer) == 16)
    {
        sendPacketToInstance16();
        //Instance 16 gets packet and calls awe_packetProcess
        receivePacketFromInstance16();
        writeReplyToServer();
    }
}
</pre> <h2>Latency <a class="anchor" id="latency"></a></h2>
<h3>Overview of Latency in AWE Core <a class="anchor" id="latency-overview"></a></h3>
<p >This section discusses only the latency caused by the AWE Core framework. The signal processing flow, the firmware, and the hardware can all introduce additional latency to the overall system. In this discussion, a "block" of latency refers to the layout block size and the systems sample rate. For example, with a layout block size of 256 and a sample rate of 48 kHz, the latency through the AWE Core system will be in multiples of blocks of (256 / 48000) = 5.33 ms. AWECore can introduce up to 2 block’s of latency, but can also be configured to achieve 0 blocks of latency under certain conditions.</p>
<p >There are 3 possible latency situations introduced by the AWECore library</p><ul>
<li>2 blocks of latency</li>
<li>1 block of latency</li>
<li>0 blocks of latency</li>
</ul>
<p >Which of the three latency paths will be taken depends on some conditions in the implementation of the AWECore API, and the relationship between the system and the signal processing layout.</p>
<p >Note: The following abbreviations may be used for these AWECore API calls:</p><ul>
<li><a class="el" href="a00044.html#a9e4bb98b017a47c1c1cad5e897c6390b">awe_audioImportSamples</a> = Import</li>
<li><a class="el" href="a00044.html#a3e08c72e3bf11627e4fd87a99ebb6419">awe_audioPump</a> = Pump</li>
<li><a class="el" href="a00044.html#ab2a5f4c7d4228495a3af02cad79b2ee7">awe_audioExportSamples</a> = Export</li>
</ul>
<h3>Conditions that Impact Latency <a class="anchor" id="latency-conditions"></a></h3>
<p >To achieve 0 blocks of AWE-induced latency, the following three conditions must be met:</p><ol type="1">
<li>Equivalent Block Sizes: The loaded layout’s blocksize must be equivalent to the AWECore instance’s fundamental blocksize.</li>
<li>Order of audio API calls: The order of AWECore audio processing API calls in the BSP’s audio callback must be import -&gt; pump -&gt; export, as in the following: awe_audioImportSamples() -&gt; awe_audioGetPumpMask() &amp;&amp; awe_audioPump() -&gt; awe_audioExportSamples</li>
<li>awe_audioPump() Inline with DMA callback: The awe_audioPump() API for layout index 0 must be called inline with the BSP’s audio callback, as opposed to signaling another thread or raising an interrupt.</li>
</ol>
<p ><img src="../images/latencytable.png" alt="latency-table" width="600" height="145" class="inline"/></p>
<h4>Equivalent Block Sizes &ndash; Double Buffering <a class="anchor" id="latency-equal-blocksizes"></a></h4>
<p >AWE Core has an internal double buffering scheme on the input and output pins to handle situations where a layout’s blocksize is a multiple of the AWEInstance’s fundamental blocksize. For example, a system with a 64 BS layout running on a 32 fundamental BS AWEInstance must complete two, 32-sample audio callbacks before actually pumping audio through the layout (to satisfy the 64 samples). Double buffering is used in this situation in order to store the next frames of data in one buffer, while the processing occurs on the data in the other buffer. Two blocks of latency are introduced by this double buffering of the input and output pins.</p>
<p >However, in a situation where a layout BS is the same as a fundamental BS, the double buffering scheme is not required and two blocks of latency can be avoided. AWECore has an internal mechanism to check if the layout and fundamental blocksizes are equivalent at layout runtime, and will automatically bypass the double buffering to eliminate the introduced latency. Less memory is also consumed under this condition as only a single buffer can be used at the input and output pins.</p>
<h4>Order of AWECore API Calls &ndash; Import Pump Export <a class="anchor" id="latency-api-order"></a></h4>
<p >At a very high level, 0 blocks of latency can only fundamentally be achieved if all of the audio processing occurs in a single callback. Based on this, the audio processing function must implement the following order of API calls to achieve the lowest possible latency: <a class="el" href="a00044.html#a9e4bb98b017a47c1c1cad5e897c6390b">awe_audioImportSamples()</a> <a class="el" href="a00044.html#ab8882c4641a4461678acfab526f61478">awe_audioGetPumpMask()</a> &amp;&amp; <a class="el" href="a00044.html#a3e08c72e3bf11627e4fd87a99ebb6419">awe_audioPump()</a> (can be a signal to lower priority threads to do actual pumping) <a class="el" href="a00044.html#ab2a5f4c7d4228495a3af02cad79b2ee7">awe_audioExportSamples()</a></p>
<p >Different orders of API calls will still operate correctly from a processing standpoint, but may not achieve the lowest possible latency.</p>
<h4>Pump Inline with Callback &ndash; Pump Context <a class="anchor" id="latency-inline-pump"></a></h4>
<p >Virtually all systems that integrate the AWE Core will use a thread signaling or interrupt raising scheme to trigger awe_audioPump in separate, lower priority contexts from the main DMA audio callback. While this scheme is required in order to allow for efficient, multi-rate operation of signal processing layouts, it does mean that the processing of the audio signal will not be complete by the end of the audio callback, As mentioned in the section above, a system with 0 blocks of AWECore induced latency must complete all audio processing within the context of the main DMA audio callback. So in order to achieve minimal latency, the first sublayout (layout index 0) must be executed in place during the audio callback, not in a lower priority context.</p>
<p >The first sublayout consumes the input pin and fills the output pin, so it is only this layout that needs to be processed in place. Other non low latency paths (clockdivided sublayouts, layout index &gt; 0) should still be signaled by the callback and pumped in another context.</p>
<h2>Troubleshooting and Common Pitfalls<a class="anchor" id="troubleshooting"></a></h2>
<p >There are a few common pitfalls when BSP authors are integrating AWE Core. The most common problems are scheduling issues, specifically when the audio thread is not at a high enough priority and is preempted by the packet or deferred processing. RT audio needs to be running at a very high priority, just below the Tuning Interface IO thread. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.4
</small></address>
</body>
</html>
